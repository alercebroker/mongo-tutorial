{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd3e27c-921d-49a5-995e-0d9535177bb5",
   "metadata": {},
   "source": [
    "## Aggregation pipelines\n",
    "\n",
    "In MongoDB it is possible to concatenate multiple operations within a single command by using aggregation pipelines. This can include some of the things we've seen before, such as queries, projections, sorting and pagination, and also additional operations which are not available as part of the previous commands.\n",
    "\n",
    "An aggregation pipeline in MongoDB consists of one or more stage, each with their own possible operators. Most stages are rather free when it comes to the order in which they have to be used or how many times they can be used, but keep in mind that some of them have restrictions about when and how many times they can be used. We'll see here only the most common ones, but you can check the full list of stages [here](https://www.mongodb.com/docs/v6.0/reference/operator/aggregation-pipeline/#std-label-aggregation-pipeline-operator-reference).\n",
    "\n",
    "To use an aggregation pipeline in pymongo, we use the `aggregate` method for collections. This receives a list of dictionaries as its main parameter. Each dictionary must have a single key, corresponding to the pipeline stage and the value defining the working of the stage. The output of each stage will then be used as input for the following, all the way until the list is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602f927-3b00-47ac-9d8e-ed538eea303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(host='localhost', port=27017, username='mongo', password='mongo')\n",
    "\n",
    "objects = client.alerce.objects  # This is the collection we'll be using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ee6b1-2498-456a-a54f-1f2eab4e8664",
   "metadata": {},
   "source": [
    "### `$match`\n",
    "\n",
    "The stage `$match` is equivalent to performing a query and uses the same operators we've seen for the `find` method first parameter. This stage doesn't include the possibility of using a projection (there is a special stage for that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a83f9-9766-4f0d-8ae0-444356e66d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([{'$match': {'ndet': {'$gte': 400}}}])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17834aff-05d5-4e79-a967-b2923c63ca2a",
   "metadata": {},
   "source": [
    "The output of `aggregate` is a `CommandCursor`. This is different from the `Cursor` we saw for the output of `find`, but it is still iterable. \n",
    "\n",
    "Unfortunately, this type does not have the `explain` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2467b6-8360-4991-8c26-9345860d2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd4a56-7a53-4e28-b348-c0bacac81db4",
   "metadata": {},
   "source": [
    "### `$project`\n",
    "\n",
    "As the name implies, the `$project` stage is equivalent to the projection we've seen in the previous module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cf774-f93b-4c54-8756-c6a5f3a5aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([{'$project': {'ndet': True, '_id': False}}])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf247a6-f714-4c67-a613-eac32b5031bb",
   "metadata": {},
   "source": [
    "Each stage can be concatenated in any order. Keep in mind that the field being used might change due to renaming and the order of the stages. The following to blocks give the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe0dfa-3453-425c-850b-45052b71dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([\n",
    "    {'$project': {'detections': '$ndet', '_id': False}},  # Renaming the field\n",
    "    {'$match': {'detections': {'$gte': 400}}}  # We need to use the new name\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bdc47-0a68-43ce-ae4d-6ca03d82d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([\n",
    "    {'$match': {'ndet': {'$gte': 400}}},  # Using ndet    \n",
    "    {'$project': {'detections': '$ndet', '_id': False}},  # Renaming the field\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1efc45-7846-484d-9882-c867650355bb",
   "metadata": {},
   "source": [
    "However, it is important to note that, in terms of performance they are both very different. By starting with the match, we only need to rename the field for the 3 documents matched documents. Using the reverse order, we'll be renaming the field for the whole collection and then selecting the relevant documents.\n",
    "\n",
    "**It is recommended to start a pipeline with a `$match` that limits as much as possible the number of results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38688c46-aac7-40b3-9177-8403142eb465",
   "metadata": {},
   "source": [
    "### `$set`/`$addFields`\n",
    "\n",
    "These stages do the same thing, although `$set` is only available starting on MongoDB 4.2. Their behaviour is similar to that of `$project` when creating a new field. The difference comes in the fact that the new fields are added to the existing ones instead of having to select what is going to be in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff71bce-682c-44a6-b75d-ffd2b76b1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([\n",
    "    {'$match': {'ndet': {'$gte': 400}}},\n",
    "    {'$set': {'deltamjd': {'$subtract': ['$lastmjd', '$firstmjd']}}},\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43139f-0404-4d1e-96b2-f930ac63c81a",
   "metadata": {},
   "source": [
    "The new fields are always added at the end of the dictionary. More than one field can be added in a single stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439e77b-293b-4ee2-b3e2-f1b1d3958fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([\n",
    "    {'$match': {'ndet': {'$gte': 400}}},\n",
    "    {'$set': {\n",
    "        'deltamjd': {\n",
    "            '$subtract': ['$lastmjd', '$firstmjd']\n",
    "        },\n",
    "        'stamp_classified': {  # Checks if at least one of the classifier names contains 'stamp_classifier'\n",
    "            '$in': ['stamp_classifier', '$probabilities.classifier_name']\n",
    "        }\n",
    "    }},\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba4584-100f-4353-83de-5ac31591d8cb",
   "metadata": {},
   "source": [
    "### `$unwind`\n",
    "\n",
    "The stage `$unwind` is used for arrays and it will \"disarm\" the array, resulting on one document for each array element among all the retrieved documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9cc0d-3279-4271-aa64-08881660c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = objects.aggregate([\n",
    "    {'$match': {'ndet': {'$gte': 400}}},\n",
    "    {'$unwind': '$probabilities'},\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b0f70-7917-4d63-8cd4-13d12234ea9b",
   "metadata": {},
   "source": [
    "As you can see, now we retrieved repeated `_id`s, and each output document correspond to one element of the original `probabilities` array. The field `probabilities` is now an element of the array we began with.\n",
    "\n",
    "This allows us to get a single entry when searching by, for instance, class and probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18001080-41a7-44da-92d9-86986ff85c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'stamp_classifier'\n",
    "class_ = 'VS'\n",
    "min_prob = 0.7\n",
    "\n",
    "docs = objects.aggregate([\n",
    "    {\n",
    "        '$match': {\n",
    "            'probabilities': {\n",
    "                '$elemMatch': {\n",
    "                    'classifier_name': classifier,\n",
    "                    'class_name': class_,\n",
    "                    'probability': {'$gte': min_prob}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {  # Remember that in the last stage we still have the full 'probabilities' array\n",
    "        '$set': {\n",
    "            'probabilities': {\n",
    "                '$filter': {\n",
    "                    'input': '$probabilities',\n",
    "                    'cond': {\n",
    "                        '$and': [\n",
    "                            {'$eq': ['$$this.classifier_name', classifier]},\n",
    "                            {'$eq': ['$$this.class_name', class_]},\n",
    "                            {'$gte': ['$$this.probability', min_prob]}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$unwind': '$probabilities'\n",
    "    },\n",
    "])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376e0e1-7da3-4121-bb67-03cd455b8661",
   "metadata": {},
   "source": [
    "**Warning:** Unfortunately, due to how the selection of array elements works, both the `$set` and the `$match` stages should match for a query like the one above, but there is no control over it. It is very easy to be testing some queries and then forget to update the value or the field in either the `$filter` or the `$elemMatch` operators, resulting in valid but meaningless queries. *Pay close attention when creating this types of queries.* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
